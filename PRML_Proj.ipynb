{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FvAJc1-kpWZL"
      },
      "outputs": [],
      "source": [
        "path = 'resources/Language Detection.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n6Ugfx-PpXKt"
      },
      "outputs": [],
      "source": [
        "import string \n",
        "import re\n",
        "import codecs\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import feature_extraction\n",
        "from sklearn import linear_model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import itertools\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tlJ1123hpfJ6",
        "outputId": "39d565d0-d4b4-44ef-836d-cf6b7ea94c77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nature, in the broadest sense, is the natural...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The study of nature is a large, if not the onl...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Although humans are part of nature, human acti...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10332</th>\n",
              "      <td>ನಿಮ್ಮ ತಪ್ಪು ಏನು ಬಂದಿದೆಯೆಂದರೆ ಆ ದಿನದಿಂದ ನಿಮಗೆ ಒ...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10333</th>\n",
              "      <td>ನಾರ್ಸಿಸಾ ತಾನು ಮೊದಲಿಗೆ ಹೆಣಗಾಡುತ್ತಿದ್ದ ಮಾರ್ಗಗಳನ್...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10334</th>\n",
              "      <td>ಹೇಗೆ ' ನಾರ್ಸಿಸಿಸಮ್ ಈಗ ಮರಿಯನ್ ಅವರಿಗೆ ಸಂಭವಿಸಿದ ಎ...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10335</th>\n",
              "      <td>ಅವಳು ಈಗ ಹೆಚ್ಚು ಚಿನ್ನದ ಬ್ರೆಡ್ ಬಯಸುವುದಿಲ್ಲ ಎಂದು ...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10336</th>\n",
              "      <td>ಟೆರ್ರಿ ನೀವು ನಿಜವಾಗಿಯೂ ಆ ದೇವದೂತನಂತೆ ಸ್ವಲ್ಪ ಕಾಣು...</td>\n",
              "      <td>Kannada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10337 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text Language\n",
              "0       Nature, in the broadest sense, is the natural...  English\n",
              "1      \"Nature\" can refer to the phenomena of the phy...  English\n",
              "2      The study of nature is a large, if not the onl...  English\n",
              "3      Although humans are part of nature, human acti...  English\n",
              "4      [1] The word nature is borrowed from the Old F...  English\n",
              "...                                                  ...      ...\n",
              "10332  ನಿಮ್ಮ ತಪ್ಪು ಏನು ಬಂದಿದೆಯೆಂದರೆ ಆ ದಿನದಿಂದ ನಿಮಗೆ ಒ...  Kannada\n",
              "10333  ನಾರ್ಸಿಸಾ ತಾನು ಮೊದಲಿಗೆ ಹೆಣಗಾಡುತ್ತಿದ್ದ ಮಾರ್ಗಗಳನ್...  Kannada\n",
              "10334  ಹೇಗೆ ' ನಾರ್ಸಿಸಿಸಮ್ ಈಗ ಮರಿಯನ್ ಅವರಿಗೆ ಸಂಭವಿಸಿದ ಎ...  Kannada\n",
              "10335  ಅವಳು ಈಗ ಹೆಚ್ಚು ಚಿನ್ನದ ಬ್ರೆಡ್ ಬಯಸುವುದಿಲ್ಲ ಎಂದು ...  Kannada\n",
              "10336  ಟೆರ್ರಿ ನೀವು ನಿಜವಾಗಿಯೂ ಆ ದೇವದೂತನಂತೆ ಸ್ವಲ್ಪ ಕಾಣು...  Kannada\n",
              "\n",
              "[10337 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tXt7682DsO8v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Arabic' 'Danish' 'Dutch' 'English' 'French' 'German' 'Greek' 'Hindi'\n",
            " 'Italian' 'Kannada' 'Malayalam' 'Portugeese' 'Russian' 'Spanish'\n",
            " 'Sweedish' 'Tamil' 'Turkish']\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:,0]\n",
        "y = df.iloc[:,1]\n",
        "print(np.unique(y))\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "f0PtItlKwKAW",
        "outputId": "4b733935-dd21-440d-8f76-c673ae65dcf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Language', ylabel='count'>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "sns.countplot(x = df['Language'], data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emAT46QUsVEb",
        "outputId": "0e2b8234-9b20-430e-89cd-bd79e3d099b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' nature  in the broadest sense  is the natural  physical  material world or universe.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_list = []\n",
        "for text in X:\n",
        "    text = re.sub(r'[!@#$(),\"%^*?:;~`0-9]', ' ', text)\n",
        "    text = re.sub(r'[[][  ]]', ' ', text)\n",
        "    text = text.lower()\n",
        "    data_list.append(text)\n",
        "data_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "4AQVWiOEw3lg"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data_list, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DIFFERENT VECTORIZATION TECHNIQUES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "path2 = 'resources/glove.6B.50d.txt'\n",
        "embeddings_dict={}\n",
        "with open(path2,'rb') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents = [sent.split() for sent in x_train]\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_NUM_WORDS = 100\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(sents)\n",
        "sequences = tokenizer.texts_to_sequences(sents)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "EMBEDDING_DIM = embeddings_dict.get(b'a').shape[0]\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix_Glove = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dict.get(word.encode(\"utf-8\")) \n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_Glove[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Skip-Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim import models\n",
        "w2v = models.KeyedVectors.load_word2vec_format(\n",
        "'resources/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents = [sent.split() for sent in x_train]\n",
        "custom_model = models.Word2Vec(sents, min_count=1,workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(531270, 1026421)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_model.train(x_train, total_examples=1, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "tfidf = TfidfVectorizer(stop_words='english', analyzer=lambda x: x)\n",
        "logistic = LogisticRegression(solver='liblinear', multi_class='auto')\n",
        "\n",
        "tfidf_logistic = Pipeline([\n",
        "    ('tfidf', tfidf), \n",
        "    ('logistic', logistic)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import randint, uniform\n",
        "\n",
        "w2v_params = {'w2v__size': [100, 150, 200]}\n",
        "tfidf_params = {'tfidf__ngram_range': [(1, 1), (1, 2)]}\n",
        "logistic_params = {'logistic__C': [0.5, 1.0, 1.5]}\n",
        "xgb_params = {'xgb__max_depth': randint(low=3, high=12),\n",
        "              'xgb__colsample_bytree': uniform(loc=0.8, scale=0.2),\n",
        "              'xgb__subsample': uniform(loc=0.8, scale=0.2)}\n",
        "\n",
        "tfidf_logistic_params = {**tfidf_params, **logistic_params}\n",
        "w2v_xgb_params = {**w2v_params, **xgb_params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training: tfidf_logistic\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>train_score</th>\n",
              "      <th>test_score</th>\n",
              "      <th>estimator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tfidf_logistic</td>\n",
              "      <td>0.915951</td>\n",
              "      <td>0.916828</td>\n",
              "      <td>RandomizedSearchCV(cv=3,\\n                   e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model_name  train_score  test_score  \\\n",
              "0  tfidf_logistic     0.915951    0.916828   \n",
              "\n",
              "                                           estimator  \n",
              "0  RandomizedSearchCV(cv=3,\\n                   e...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "cv = 3\n",
        "n_iter = 3\n",
        "random_state = 1234\n",
        "scoring = 'accuracy'\n",
        "\n",
        "all_models = [\n",
        "    ('tfidf_logistic', tfidf_logistic, tfidf_logistic_params)\n",
        "]\n",
        "\n",
        "all_models_info = []\n",
        "for name, model, params in all_models:\n",
        "    print('training:', name)\n",
        "    model_tuned = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=params,\n",
        "        cv=cv,\n",
        "        n_iter=n_iter,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        scoring=scoring,\n",
        "        random_state=random_state,\n",
        "        return_train_score=False\n",
        "    ).fit(x_train, y_train)\n",
        "    \n",
        "    y_test_pred = model_tuned.predict(x_test)\n",
        "    test_score = accuracy_score(y_test, y_test_pred)\n",
        "    info = name, model_tuned.best_score_, test_score, model_tuned\n",
        "    all_models_info.append(info)\n",
        "\n",
        "columns = ['model_name', 'train_score', 'test_score', 'estimator']\n",
        "results = pd.DataFrame(all_models_info, columns=columns)\n",
        "results = (results\n",
        "           .sort_values('test_score', ascending=False)\n",
        "           .reset_index(drop=True))\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PQKnpXbpwYxH"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(3,5),analyzer='char')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents1 = x_train\n",
        "sents2 = x_test\n",
        "transformed1 = tfidf.fit_transform(sents1)\n",
        "transformed2 = tfidf.transform(sents2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sents = x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X_count_train = cv.fit_transform(sents)\n",
        "X_count_test = cv.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LATER SHIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "4wzTsYcLwaku",
        "outputId": "baee339e-5add-4b7c-9a6c-3aff2f94eb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__alpha', 'clf__class_prior', 'clf__fit_prior'])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_clf = pipeline.Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "\n",
        "print(text_clf.get_params().keys())\n",
        "text_clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hgAbGZ40jq",
        "outputId": "924c4e48-0d6d-46cc-e638-dd34c4cc6667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       110\n",
            "           1       0.99      0.90      0.94        84\n",
            "           2       0.99      0.97      0.98        96\n",
            "           3       0.83      1.00      0.91       278\n",
            "           4       0.97      0.99      0.98       202\n",
            "           5       1.00      0.98      0.99       101\n",
            "           6       1.00      0.94      0.97        72\n",
            "           7       1.00      0.62      0.77        16\n",
            "           8       0.99      0.96      0.98       142\n",
            "           9       1.00      0.97      0.98        63\n",
            "          10       1.00      0.98      0.99       133\n",
            "          11       0.99      0.99      0.99       143\n",
            "          12       1.00      0.97      0.98       127\n",
            "          13       0.98      0.99      0.99       166\n",
            "          14       0.97      0.99      0.98       137\n",
            "          15       1.00      0.99      1.00       111\n",
            "          16       1.00      0.77      0.87        87\n",
            "\n",
            "    accuracy                           0.96      2068\n",
            "   macro avg       0.98      0.94      0.96      2068\n",
            "weighted avg       0.97      0.96      0.96      2068\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, text_clf.predict(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M61xsnZ97WrF",
        "outputId": "56873232-4549-4392-86c2-5aafe26c3099"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9647001934235977"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, text_clf.predict(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_ET3X03tHIh",
        "outputId": "e1433220-1070-4631-96f8-302d3c15ce2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['resources/cv.pkl']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv = CountVectorizer()\n",
        "X_new = cv.fit_transform(data_list).toarray()\n",
        "joblib.dump(cv, \"resources/cv.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "Uv6ZtF2C-gmU"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8O2YAqutLnF",
        "outputId": "cd0969a8-1acb-44fb-9ef5-16a5f6bbe218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9753384912959381\n"
          ]
        }
      ],
      "source": [
        "model1 = MultinomialNB()\n",
        "model1.fit(x_train, y_train)\n",
        "y_pred = model1.predict(x_test)\n",
        "ac1 = accuracy_score(y_test, y_pred)\n",
        "print(ac1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f2WGTr_ue9K",
        "outputId": "ec5a2051-7660-4f0c-b791-cb79cfa69c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9796905222437138\n"
          ]
        }
      ],
      "source": [
        "model2 = GaussianNB()\n",
        "model2.fit(x_train, y_train)\n",
        "y_pred = model2.predict(x_test)\n",
        "ac2 = accuracy_score(y_test, y_pred)\n",
        "print(ac2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## implimenting NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10337, 17)"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#one hot encode the target variable\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "dummy_y = tf.keras.utils.to_categorical(encoded_Y)\n",
        "dummy_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_Y = encoded_Y.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train = x_train.values\n",
        "# X_test = x_test.values\n",
        "X_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "X_test = dummy_y.reshape(dummy_y.shape[0], dummy_y.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Implement neural network using tensorflow\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=128, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=256, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=128, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "#ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dropout(0.2))\n",
        "ann.add(tf.keras.layers.Dense(units = 17, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3.,  3.,  1., ...,  8., 11.,  1.], dtype=float32)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "324/324 [==============================] - 8s 22ms/step - loss: 0.4371 - accuracy: 0.8926\n",
            "Epoch 2/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0342 - accuracy: 0.9919\n",
            "Epoch 3/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0158 - accuracy: 0.9968\n",
            "Epoch 4/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0120 - accuracy: 0.9969\n",
            "Epoch 5/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0093 - accuracy: 0.9975\n",
            "Epoch 6/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0100 - accuracy: 0.9971\n",
            "Epoch 7/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0119 - accuracy: 0.9966\n",
            "Epoch 8/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 9/10\n",
            "324/324 [==============================] - 7s 20ms/step - loss: 0.0099 - accuracy: 0.9968\n",
            "Epoch 10/10\n",
            "324/324 [==============================] - 7s 21ms/step - loss: 0.0088 - accuracy: 0.9974\n"
          ]
        }
      ],
      "source": [
        "ann.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "ann.fit(X_new,encoded_Y, epochs=10, batch_size=32)\n",
        "ann.save('resources/language_predictor.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9622823984526112\n",
            "0.9590643420165255\n"
          ]
        }
      ],
      "source": [
        "dummy_y_test = tf.keras.utils.to_categorical(encoder.transform(y_test))\n",
        "print(accuracy_score(y_test, np.argmax(ann.predict(x_test), axis=1)))\n",
        "print(f1_score(y_test, np.argmax(ann.predict(x_test), axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## nearest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train,x_val = train_test_split(x_train, test_size=0.2)\n",
        "y_train,y_val = train_test_split(y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_k(x_train, y_train, x_val, y_val):\n",
        "    best_k = 0\n",
        "    best_score = 0\n",
        "    for k in range(1, 11):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(x_train, y_train)\n",
        "        pred = knn.predict(x_val)\n",
        "        score = f1_score(y_val, pred, average='macro')\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_k = k\n",
        "    return best_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_best_k(x_train, y_train, x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0672147001934236\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#concat train and val\n",
        "x_train = np.concatenate((x_train, x_val), axis=0)\n",
        "y_train = np.concatenate((y_train, y_val), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jahna\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        }
      ],
      "source": [
        "clf = XGBClassifier(random_state = 0)\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, MaxPooling1D, Conv1D\n",
        "from keras.models import Sequential,Model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.merge import Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    embeddings_index = {}\n",
        "    f = open(path2, encoding=\"utf8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "        except:\n",
        "            pass\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_index))\n",
        "    return (X_train, X_test, word_index,embeddings_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Build_Model_CNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
        "    \"\"\"\n",
        "        def buildModel_CNN(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
        "        word_index in word index ,\n",
        "        embeddings_index is embeddings index, look at data_helper.py\n",
        "        nClasses is number of classes,\n",
        "        MAX_SEQUENCE_LENGTH is maximum lenght of text sequences,\n",
        "        EMBEDDING_DIM is an int value for dimention of word embedding look at data_helper.py\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
        "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
        "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    embedding_layer = Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True)\n",
        "    # applying a more complex convolutional approach\n",
        "    convs = []\n",
        "    filter_sizes = []\n",
        "    layer = 5\n",
        "    print(\"Filter  \",layer)\n",
        "    for fl in range(0,layer):\n",
        "        filter_sizes.append((fl+2))\n",
        "    node = 128\n",
        "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    for fsz in filter_sizes:\n",
        "        l_conv = Conv1D(node, kernel_size=fsz, activation='relu')(embedded_sequences)\n",
        "        l_pool = MaxPooling1D(5)(l_conv)\n",
        "        #l_pool = Dropout(0.25)(l_pool)\n",
        "        convs.append(l_pool)\n",
        "    l_merge = Concatenate(axis=1)(convs)\n",
        "    l_cov1 = Conv1D(node, 5, activation='relu')(l_merge)\n",
        "    l_cov1 = Dropout(dropout)(l_cov1)\n",
        "    l_pool1 = MaxPooling1D(5)(l_cov1)\n",
        "    l_cov2 = Conv1D(node, 5, activation='relu')(l_pool1)\n",
        "    l_cov2 = Dropout(dropout)(l_cov2)\n",
        "    l_pool2 = MaxPooling1D(30)(l_cov2)\n",
        "    l_flat = Flatten()(l_pool2)\n",
        "    l_dense = Dense(1024, activation='relu')(l_flat)\n",
        "    l_dense = Dropout(dropout)(l_dense)\n",
        "    l_dense = Dense(512, activation='relu')(l_dense)\n",
        "    l_dense = Dropout(dropout)(l_dense)\n",
        "    preds = Dense(nclasses, activation='softmax')(l_dense)\n",
        "    model = Model(sequence_input, preds)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PRML_Proj.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
